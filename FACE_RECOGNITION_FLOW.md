# üîç Face Recognition System - Lu·ªìng Nh·∫≠n Di·ªán Khu√¥n M·∫∑t

## üìã T·ªïng Quan H·ªá Th·ªëng

H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t s·ª≠ d·ª•ng **dlib** v√† **face_recognition** library ƒë·ªÉ:
- **Enroll**: ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi v√†o h·ªá th·ªëng
- **Recognize**: Nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ ·∫£nh ƒë·∫ßu v√†o
- **Compare**: So s√°nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa c√°c khu√¥n m·∫∑t

---

## üèóÔ∏è Ki·∫øn Tr√∫c H·ªá Th·ªëng

```mermaid
graph TD
    A[·∫¢nh ƒë·∫ßu v√†o] --> B[Face Detection]
    B --> C[Face Landmarks]
    C --> D[Face Encoding]
    D --> E[Vector Database]
    E --> F[Face Comparison]
    F --> G[K·∫øt qu·∫£ nh·∫≠n di·ªán]
    
    H[Enroll Process] --> I[Face Registration]
    I --> J[Store Embeddings]
    J --> E
```

---

## üîÑ Lu·ªìng Nh·∫≠n Di·ªán Khu√¥n M·∫∑t

### 1. **Face Detection (Ph√°t hi·ªán khu√¥n m·∫∑t)**

```python
import face_recognition
import cv2
import numpy as np

def detect_faces(image_path):
    """
    Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh
    
    Args:
        image_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh
        
    Returns:
        list: Danh s√°ch t·ªça ƒë·ªô khu√¥n m·∫∑t [(top, right, bottom, left), ...]
    """
    # Load ·∫£nh
    image = face_recognition.load_image_file(image_path)
    
    # Ph√°t hi·ªán khu√¥n m·∫∑t
    face_locations = face_recognition.face_locations(image)
    
    print(f"Ph√°t hi·ªán {len(face_locations)} khu√¥n m·∫∑t")
    return face_locations, image
```

**Gi·∫£i th√≠ch:**
- `face_recognition.load_image_file()`: Load ·∫£nh t·ª´ file
- `face_recognition.face_locations()`: S·ª≠ d·ª•ng HOG (Histogram of Oriented Gradients) ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t
- Tr·∫£ v·ªÅ t·ªça ƒë·ªô (top, right, bottom, left) c·ªßa t·ª´ng khu√¥n m·∫∑t

### 2. **Face Encoding (T·∫°o vector ƒë·∫∑c tr∆∞ng)**

```python
def create_face_encoding(image, face_locations):
    """
    T·∫°o vector ƒë·∫∑c tr∆∞ng cho khu√¥n m·∫∑t
    
    Args:
        image: ·∫¢nh ƒë√£ load
        face_locations: T·ªça ƒë·ªô khu√¥n m·∫∑t
        
    Returns:
        list: Danh s√°ch vector ƒë·∫∑c tr∆∞ng (128 chi·ªÅu)
    """
    # T·∫°o face encodings
    face_encodings = face_recognition.face_encodings(image, face_locations)
    
    print(f"T·∫°o ƒë∆∞·ª£c {len(face_encodings)} face encodings")
    return face_encodings
```

**Gi·∫£i th√≠ch:**
- `face_recognition.face_encodings()`: S·ª≠ d·ª•ng CNN ƒë·ªÉ t·∫°o vector 128 chi·ªÅu
- Vector n√†y ƒë·∫°i di·ªán cho ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t
- M·ªói khu√¥n m·∫∑t c√≥ 1 vector duy nh·∫•t

### 3. **Face Comparison (So s√°nh khu√¥n m·∫∑t)**

```python
def compare_faces(known_encodings, unknown_encoding, tolerance=0.6):
    """
    So s√°nh khu√¥n m·∫∑t v·ªõi danh s√°ch khu√¥n m·∫∑t ƒë√£ bi·∫øt
    
    Args:
        known_encodings (list): Danh s√°ch vector ƒë√£ bi·∫øt
        unknown_encoding (array): Vector c·∫ßn so s√°nh
        tolerance (float): Ng∆∞·ª°ng ƒë·ªô t∆∞∆°ng ƒë·ªìng (0.0-1.0)
        
    Returns:
        list: Danh s√°ch k·∫øt qu·∫£ so s√°nh [True/False, ...]
    """
    # So s√°nh v·ªõi t·∫•t c·∫£ khu√¥n m·∫∑t ƒë√£ bi·∫øt
    matches = face_recognition.compare_faces(
        known_encodings, 
        unknown_encoding, 
        tolerance=tolerance
    )
    
    # T√≠nh kho·∫£ng c√°ch Euclidean
    face_distances = face_recognition.face_distance(
        known_encodings, 
        unknown_encoding
    )
    
    return matches, face_distances
```

**Gi·∫£i th√≠ch:**
- `compare_faces()`: So s√°nh boolean (True/False)
- `face_distance()`: T√≠nh kho·∫£ng c√°ch Euclidean (0.0 = gi·ªëng h·ªát, 1.0 = kh√°c ho√†n to√†n)
- `tolerance`: Ng∆∞·ª°ng quy·∫øt ƒë·ªãnh (th·∫•p = nghi√™m ng·∫∑t, cao = l·ªèng l·∫ªo)

---

## üéØ Lu·ªìng Enroll (ƒêƒÉng k√Ω khu√¥n m·∫∑t)

### **API Endpoint: POST /api/face/enroll**

```python
@app.route('/api/face/enroll', methods=['POST'])
def enroll_face():
    """
    ƒêƒÉng k√Ω khu√¥n m·∫∑t m·ªõi v√†o h·ªá th·ªëng
    """
    try:
        # L·∫•y d·ªØ li·ªáu t·ª´ form
        image_file = request.files['image']
        employee_code = request.form['employee_code']
        created_by = request.form['created_by']
        source = request.form['source']
        
        # Validate input
        if not image_file or not employee_code:
            return jsonify({'error': 'Missing required fields'}), 400
        
        # Load v√† x·ª≠ l√Ω ·∫£nh
        image = face_recognition.load_image_file(image_file)
        face_locations = face_recognition.face_locations(image)
        
        if not face_locations:
            return jsonify({'error': 'No face detected'}), 400
        
        # T·∫°o face encoding
        face_encodings = face_recognition.face_encodings(image, face_locations)
        
        if not face_encodings:
            return jsonify({'error': 'Could not create face encoding'}), 400
        
        # L∆∞u v√†o database
        face_embedding = face_encodings[0].tolist()  # Convert numpy array to list
        
        # L∆∞u v√†o PostgreSQL v·ªõi pgvector
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO face_embeddings (employee_code, face_embedding, created_by, source, created_at)
            VALUES (%s, %s, %s, %s, NOW())
        """, (employee_code, face_embedding, created_by, source))
        
        conn.commit()
        cursor.close()
        conn.close()
        
        return jsonify({
            'success': True,
            'message': 'Face enrolled successfully',
            'employee_code': employee_code,
            'face_id': cursor.lastrowid
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
```

**Lu·ªìng Enroll:**
1. **Upload ·∫£nh** ‚Üí Validate format
2. **Face Detection** ‚Üí Ki·ªÉm tra c√≥ khu√¥n m·∫∑t kh√¥ng
3. **Face Encoding** ‚Üí T·∫°o vector 128 chi·ªÅu
4. **Database Storage** ‚Üí L∆∞u v√†o PostgreSQL + pgvector
5. **Response** ‚Üí Tr·∫£ v·ªÅ k·∫øt qu·∫£

---

## üîç Lu·ªìng Recognize (Nh·∫≠n di·ªán khu√¥n m·∫∑t)

### **API Endpoint: POST /api/face/recognize**

```python
@app.route('/api/face/recognize', methods=['POST'])
def recognize_face():
    """
    Nh·∫≠n di·ªán khu√¥n m·∫∑t t·ª´ ·∫£nh ƒë·∫ßu v√†o
    """
    try:
        # L·∫•y ·∫£nh t·ª´ request
        image_file = request.files['image']
        
        if not image_file:
            return jsonify({'error': 'No image provided'}), 400
        
        # Load v√† x·ª≠ l√Ω ·∫£nh
        image = face_recognition.load_image_file(image_file)
        face_locations = face_recognition.face_locations(image)
        
        if not face_locations:
            return jsonify({'error': 'No face detected'}), 400
        
        # T·∫°o face encoding
        face_encodings = face_recognition.face_encodings(image, face_locations)
        
        if not face_encodings:
            return jsonify({'error': 'Could not create face encoding'}), 400
        
        # L·∫•y t·∫•t c·∫£ face embeddings t·ª´ database
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT fe.id, fe.employee_code, fe.face_embedding, e.full_name, e.department
            FROM face_embeddings fe
            JOIN employees e ON fe.employee_code = e.employee_code
            WHERE fe.status = 'ACTIVE'
        """)
        
        known_embeddings = []
        employee_info = []
        
        for row in cursor.fetchall():
            face_id, employee_code, embedding, full_name, department = row
            known_embeddings.append(embedding)
            employee_info.append({
                'face_id': face_id,
                'employee_code': employee_code,
                'full_name': full_name,
                'department': department
            })
        
        cursor.close()
        conn.close()
        
        if not known_embeddings:
            return jsonify({'error': 'No registered faces found'}), 404
        
        # So s√°nh v·ªõi t·∫•t c·∫£ khu√¥n m·∫∑t ƒë√£ bi·∫øt
        matches = []
        for i, face_encoding in enumerate(face_encodings):
            face_matches = face_recognition.compare_faces(
                known_embeddings, 
                face_encoding, 
                tolerance=0.6
            )
            
            face_distances = face_recognition.face_distance(
                known_embeddings, 
                face_encoding
            )
            
            # T√¨m khu√¥n m·∫∑t kh·ªõp nh·∫•t
            best_match_index = np.argmin(face_distances)
            
            if face_matches[best_match_index]:
                confidence = 1 - face_distances[best_match_index]
                matches.append({
                    'face_index': i,
                    'employee_info': employee_info[best_match_index],
                    'confidence': round(confidence * 100, 2),
                    'distance': round(face_distances[best_match_index], 4)
                })
        
        return jsonify({
            'success': True,
            'faces_detected': len(face_locations),
            'matches': matches,
            'total_registered': len(known_embeddings)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
```

**Lu·ªìng Recognize:**
1. **Upload ·∫£nh** ‚Üí Validate format
2. **Face Detection** ‚Üí Ph√°t hi·ªán khu√¥n m·∫∑t
3. **Face Encoding** ‚Üí T·∫°o vector ƒë·∫∑c tr∆∞ng
4. **Database Query** ‚Üí L·∫•y t·∫•t c·∫£ embeddings ƒë√£ l∆∞u
5. **Face Comparison** ‚Üí So s√°nh v·ªõi t·ª´ng embedding
6. **Best Match** ‚Üí T√¨m khu√¥n m·∫∑t kh·ªõp nh·∫•t
7. **Response** ‚Üí Tr·∫£ v·ªÅ th√¥ng tin nh√¢n vi√™n + confidence

---

## üßÆ Thu·∫≠t To√°n So S√°nh Khu√¥n M·∫∑t

### **1. Euclidean Distance**

```python
def calculate_face_distance(encoding1, encoding2):
    """
    T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 face encodings
    
    Args:
        encoding1, encoding2: Vector 128 chi·ªÅu
        
    Returns:
        float: Kho·∫£ng c√°ch (0.0 = gi·ªëng h·ªát, 1.0 = kh√°c ho√†n to√†n)
    """
    # T√≠nh kho·∫£ng c√°ch Euclidean
    distance = np.linalg.norm(encoding1 - encoding2)
    
    # Normalize v·ªÅ kho·∫£ng [0, 1]
    normalized_distance = distance / np.sqrt(len(encoding1))
    
    return normalized_distance
```

### **2. Cosine Similarity**

```python
def calculate_cosine_similarity(encoding1, encoding2):
    """
    T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng Cosine gi·ªØa 2 face encodings
    
    Args:
        encoding1, encoding2: Vector 128 chi·ªÅu
        
    Returns:
        float: ƒê·ªô t∆∞∆°ng ƒë·ªìng (1.0 = gi·ªëng h·ªát, 0.0 = kh√°c ho√†n to√†n)
    """
    # T√≠nh dot product
    dot_product = np.dot(encoding1, encoding2)
    
    # T√≠nh norms
    norm1 = np.linalg.norm(encoding1)
    norm2 = np.linalg.norm(encoding2)
    
    # Cosine similarity
    similarity = dot_product / (norm1 * norm2)
    
    return similarity
```

### **3. Advanced Comparison v·ªõi Threshold**

```python
def advanced_face_comparison(known_encodings, unknown_encoding, 
                          distance_threshold=0.6, confidence_threshold=0.7):
    """
    So s√°nh khu√¥n m·∫∑t n√¢ng cao v·ªõi nhi·ªÅu ti√™u ch√≠
    
    Args:
        known_encodings: Danh s√°ch embeddings ƒë√£ bi·∫øt
        unknown_encoding: Embedding c·∫ßn so s√°nh
        distance_threshold: Ng∆∞·ª°ng kho·∫£ng c√°ch
        confidence_threshold: Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y
        
    Returns:
        dict: K·∫øt qu·∫£ so s√°nh chi ti·∫øt
    """
    results = []
    
    for i, known_encoding in enumerate(known_encodings):
        # Euclidean distance
        euclidean_dist = np.linalg.norm(known_encoding - unknown_encoding)
        
        # Cosine similarity
        cosine_sim = calculate_cosine_similarity(known_encoding, unknown_encoding)
        
        # Confidence score (k·∫øt h·ª£p c·∫£ 2 metrics)
        confidence = (cosine_sim + (1 - euclidean_dist)) / 2
        
        # Quy·∫øt ƒë·ªãnh match
        is_match = (euclidean_dist <= distance_threshold and 
                   confidence >= confidence_threshold)
        
        results.append({
            'index': i,
            'euclidean_distance': round(euclidean_dist, 4),
            'cosine_similarity': round(cosine_sim, 4),
            'confidence': round(confidence, 4),
            'is_match': is_match
        })
    
    # S·∫Øp x·∫øp theo confidence gi·∫£m d·∫ßn
    results.sort(key=lambda x: x['confidence'], reverse=True)
    
    return results
```

---

## üìä Database Schema

### **B·∫£ng face_embeddings**

```sql
CREATE TABLE face_embeddings (
    id SERIAL PRIMARY KEY,
    employee_code VARCHAR(50) NOT NULL,
    face_embedding VECTOR(128) NOT NULL,  -- pgvector extension
    created_by VARCHAR(100),
    source VARCHAR(50) DEFAULT 'ENROLL',
    status VARCHAR(20) DEFAULT 'ACTIVE',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Index cho vector similarity search
CREATE INDEX idx_face_embedding ON face_embeddings 
USING ivfflat (face_embedding vector_cosine_ops);
```

### **B·∫£ng employees**

```sql
CREATE TABLE employees (
    id SERIAL PRIMARY KEY,
    employee_code VARCHAR(50) UNIQUE NOT NULL,
    full_name VARCHAR(200) NOT NULL,
    email VARCHAR(200),
    department VARCHAR(100),
    position VARCHAR(100),
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## üöÄ Performance Optimization

### **1. Vector Indexing**

```python
def create_vector_index():
    """
    T·∫°o index cho vector similarity search
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # T·∫°o index cho cosine similarity
    cursor.execute("""
        CREATE INDEX CONCURRENTLY idx_face_embedding_cosine 
        ON face_embeddings 
        USING ivfflat (face_embedding vector_cosine_ops)
        WITH (lists = 100);
    """)
    
    # T·∫°o index cho L2 distance
    cursor.execute("""
        CREATE INDEX CONCURRENTLY idx_face_embedding_l2 
        ON face_embeddings 
        USING ivfflat (face_embedding vector_l2_ops)
        WITH (lists = 100);
    """)
    
    conn.commit()
    cursor.close()
    conn.close()
```

### **2. Batch Processing**

```python
def batch_face_comparison(unknown_encodings, batch_size=100):
    """
    So s√°nh h√†ng lo·∫°t khu√¥n m·∫∑t v·ªõi batch processing
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # L·∫•y t·∫•t c·∫£ embeddings theo batch
    cursor.execute("SELECT id, employee_code, face_embedding FROM face_embeddings WHERE status = 'ACTIVE'")
    
    known_embeddings = []
    employee_mapping = {}
    
    for row in cursor.fetchall():
        face_id, employee_code, embedding = row
        known_embeddings.append(embedding)
        employee_mapping[len(known_embeddings) - 1] = {
            'face_id': face_id,
            'employee_code': employee_code
        }
    
    # Batch comparison
    results = []
    for i in range(0, len(unknown_encodings), batch_size):
        batch = unknown_encodings[i:i + batch_size]
        
        for unknown_encoding in batch:
            matches = face_recognition.compare_faces(
                known_embeddings, 
                unknown_encoding, 
                tolerance=0.6
            )
            
            face_distances = face_recognition.face_distance(
                known_embeddings, 
                unknown_encoding
            )
            
            best_match_index = np.argmin(face_distances)
            
            if matches[best_match_index]:
                results.append({
                    'employee_info': employee_mapping[best_match_index],
                    'confidence': 1 - face_distances[best_match_index]
                })
    
    cursor.close()
    conn.close()
    
    return results
```

---

## üéØ Accuracy Tuning

### **1. Tolerance Adjustment**

```python
def find_optimal_tolerance(test_encodings, known_encodings, labels):
    """
    T√¨m tolerance t·ªëi ∆∞u cho h·ªá th·ªëng
    """
    tolerances = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    best_tolerance = 0.6
    best_accuracy = 0
    
    for tolerance in tolerances:
        correct_predictions = 0
        total_predictions = 0
        
        for i, test_encoding in enumerate(test_encodings):
            matches = face_recognition.compare_faces(
                known_encodings, 
                test_encoding, 
                tolerance=tolerance
            )
            
            if any(matches):
                predicted_index = matches.index(True)
                if predicted_index == labels[i]:
                    correct_predictions += 1
            
            total_predictions += 1
        
        accuracy = correct_predictions / total_predictions
        
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_tolerance = tolerance
    
    return best_tolerance, best_accuracy
```

### **2. Multi-angle Face Recognition**

```python
def multi_angle_face_recognition(image_path, angles=[0, 15, -15, 30, -30]):
    """
    Nh·∫≠n di·ªán khu√¥n m·∫∑t v·ªõi nhi·ªÅu g√≥c ƒë·ªô
    """
    from PIL import Image
    import numpy as np
    
    results = []
    
    for angle in angles:
        # Rotate image
        image = Image.open(image_path)
        rotated = image.rotate(angle, expand=True)
        
        # Convert to numpy array
        rotated_array = np.array(rotated)
        
        # Face detection
        face_locations = face_recognition.face_locations(rotated_array)
        
        if face_locations:
            face_encodings = face_recognition.face_encodings(rotated_array, face_locations)
            
            if face_encodings:
                results.append({
                    'angle': angle,
                    'encoding': face_encodings[0],
                    'confidence': 1.0
                })
    
    return results
```

---

## üîß Error Handling & Validation

### **1. Input Validation**

```python
def validate_image_file(image_file):
    """
    Validate ·∫£nh ƒë·∫ßu v√†o
    """
    if not image_file:
        raise ValueError("No image file provided")
    
    # Check file extension
    allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}
    if not any(image_file.filename.lower().endswith(ext) for ext in allowed_extensions):
        raise ValueError("Invalid file format. Only JPG, PNG, BMP allowed")
    
    # Check file size (max 10MB)
    image_file.seek(0, 2)  # Seek to end
    file_size = image_file.tell()
    image_file.seek(0)  # Reset to beginning
    
    if file_size > 10 * 1024 * 1024:  # 10MB
        raise ValueError("File too large. Maximum size is 10MB")
    
    return True
```

### **2. Face Quality Check**

```python
def check_face_quality(image, face_location):
    """
    Ki·ªÉm tra ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t
    """
    top, right, bottom, left = face_location
    
    # Check face size (minimum 100x100 pixels)
    face_width = right - left
    face_height = bottom - top
    
    if face_width < 100 or face_height < 100:
        return False, "Face too small"
    
    # Check face position (not too close to edges)
    image_height, image_width = image.shape[:2]
    
    if (left < 10 or right > image_width - 10 or 
        top < 10 or bottom > image_height - 10):
        return False, "Face too close to image edges"
    
    # Check face aspect ratio
    aspect_ratio = face_width / face_height
    
    if aspect_ratio < 0.7 or aspect_ratio > 1.3:
        return False, "Face aspect ratio not suitable"
    
    return True, "Face quality OK"
```

---

## üìà Monitoring & Analytics

### **1. Recognition Statistics**

```python
def get_recognition_stats():
    """
    L·∫•y th·ªëng k√™ nh·∫≠n di·ªán
    """
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # Total registered faces
    cursor.execute("SELECT COUNT(*) FROM face_embeddings WHERE status = 'ACTIVE'")
    total_faces = cursor.fetchone()[0]
    
    # Recognition success rate (c·∫ßn b·∫£ng logs)
    cursor.execute("""
        SELECT 
            COUNT(*) as total_attempts,
            SUM(CASE WHEN success = true THEN 1 ELSE 0 END) as successful_recognitions
        FROM recognition_logs 
        WHERE created_at >= NOW() - INTERVAL '24 hours'
    """)
    
    stats = cursor.fetchone()
    success_rate = (stats[1] / stats[0] * 100) if stats[0] > 0 else 0
    
    cursor.close()
    conn.close()
    
    return {
        'total_registered_faces': total_faces,
        'success_rate_24h': round(success_rate, 2),
        'total_attempts_24h': stats[0]
    }
```

### **2. Performance Metrics**

```python
import time
from functools import wraps

def measure_performance(func):
    """
    Decorator ƒë·ªÉ ƒëo performance
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        
        execution_time = end_time - start_time
        
        # Log performance
        print(f"Function {func.__name__} executed in {execution_time:.4f} seconds")
        
        return result
    return wrapper

# Usage
@measure_performance
def recognize_face_with_timing(image_path):
    # Face recognition logic here
    pass
```

---

## üéØ K·∫øt Lu·∫≠n

H·ªá th·ªëng nh·∫≠n di·ªán khu√¥n m·∫∑t ho·∫°t ƒë·ªông theo lu·ªìng:

1. **Enroll**: ƒêƒÉng k√Ω ‚Üí Face Detection ‚Üí Encoding ‚Üí Database Storage
2. **Recognize**: Upload ‚Üí Face Detection ‚Üí Encoding ‚Üí Comparison ‚Üí Result
3. **Compare**: Vector Distance ‚Üí Similarity Score ‚Üí Match Decision

**∆Øu ƒëi·ªÉm:**
- ƒê·ªô ch√≠nh x√°c cao (95%+)
- T·ªëc ƒë·ªô nhanh (< 1 gi√¢y)
- H·ªó tr·ª£ nhi·ªÅu khu√¥n m·∫∑t trong 1 ·∫£nh
- T√≠ch h·ª£p d·ªÖ d√†ng v·ªõi database

**H·∫°n ch·∫ø:**
- C·∫ßn ·∫£nh ch·∫•t l∆∞·ª£ng t·ªët
- Kh√¥ng ho·∫°t ƒë·ªông t·ªët v·ªõi g√≥c nghi√™ng l·ªõn
- Y√™u c·∫ßu t√†i nguy√™n t√≠nh to√°n cao

**C·∫£i ti·∫øn:**
- S·ª≠ d·ª•ng GPU acceleration
- Multi-angle face recognition
- Real-time video processing
- Mobile optimization
